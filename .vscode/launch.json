{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "train llama",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/train.py",
            "args": [
                "--model_name_or_path=Llama-2-7b-hf",
                "--data_path=alpaca_data_cleaned.json",
                "--bf16=True",
                "--output_dir=sft_7b",
                "--num_train_epochs=1",
                "--per_device_train_batch_size=4",
                "--per_device_eval_batch_size=4",
                "--gradient_accumulation_steps=8",
                "--evaluation_strategy=no",
                "--save_strategy=steps",
                "--save_steps=2000",
                "--save_total_limit=1",
                "--learning_rate=2e-5",
                "--weight_decay=0.",
                "--warmup_ratio=0.03",
                "--lr_scheduler_type=cosine",
                "--logging_steps=1",
                "--report_to=tensorboard",
                "--fsdp=full_shard auto_wrap",
                "--fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer",
                "--tf32=True"
            ],
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            }
        },
        {
            "name": "train glm-lora",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/train.py",
            "args": [
                "--model_name_or_path=THUDM/chatglm-6b",
                "--data_path=alpaca_data_cleaned.json",
                "--lora_rank=8",
                "--num_train_epochs=1",
                "--per_device_train_batch_size=6",
                "--gradient_accumulation_steps=1",
                "--save_steps=2000",
                "--save_total_limit=1",
                "--learning_rate=1e-4",
                "--fp16",
                "--remove_unused_columns=false",
                "--logging_steps=50",
                "--output_dir=chatglm-6b-lora"
            ],
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            }
        }
    ]
}